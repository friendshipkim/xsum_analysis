{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418ff8f9",
   "metadata": {},
   "source": [
    "# Load datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad6821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from xsum_dataset import XsumDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93660df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/wk247/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7186c3dbecc54868a29c19aa28db6b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsum_data_raw = datasets.load_dataset(\"xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98f3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/val/test data\n",
    "# xsum_train_data = XsumDataset(xsum_data_raw[\"train\"])\n",
    "# xsum_val_data = XsumDataset(xsum_data_raw[\"validation\"])\n",
    "# xsum_test_data = XsumDataset(xsum_data_raw[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7508d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_test_data = XsumDataset(xsum_data_raw[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b82261",
   "metadata": {},
   "source": [
    "# concat data\n",
    "xsum_data_raw_cc = datasets.concatenate_datasets(\n",
    "    [xsum_data_raw[\"train\"], xsum_data_raw[\"validation\"], xsum_data_raw[\"test\"]]\n",
    "    )\n",
    "xsum_concat_data = XsumDataset(xsum_data_raw_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfd3bc",
   "metadata": {},
   "source": [
    "## select a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfff2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48a5a2",
   "metadata": {},
   "source": [
    "### * one to be perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f70a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35616768'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample one bbcid\n",
    "bbc_id = random.choice(list(xsum_test_data.data_by_id.keys()))\n",
    "# or fix one: bbc_ids = [\"33858956\"]\n",
    "bbc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9fcb44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original doc to summarize:\n",
      " The agreement, reached late on Friday after two days of talks in Brussels, gives the UK power to limit some EU migrants' benefits.\n",
      "It also includes a treaty change so the UK is not bound to \"ever closer union\" with other EU member states, he said.\n",
      "EU exit campaigners said the \"hollow\" deal offered only \"very minor changes\".\n",
      "Mr Cameron is set to the announce the date of a referendum on whether Britain should remain in the EU after a cabinet meeting which is happening at 10:00 GMT - the referendum is widely expected to be on Thursday, 23 June.\n",
      "Once the date is announced, ministers will be allowed to campaign for whichever side they want - one of Mr Cameron's closest political allies Michael Gove has already been named as supporting the Leave camp. Others, such as Iain Duncan Smith are expected to follow - but a question mark remains over which way London Mayor Boris Johnson will jump.\n",
      "The key points of the deal are:\n",
      "The prime minster had to make concessions to get a deal with the leaders of the 27 other EU members.\n",
      "Mr Cameron had originally wanted a complete ban on migrants sending child benefit abroad but had to compromise after some eastern European states rejected that and also insisted that existing claimants should continue to receive the full payment.\n",
      "On how long the UK would be able to have a four-year curb on in-work benefits for new arrivals,  Mr Cameron had to give way on hopes of it being in place for 13 years, settling for seven instead.\n",
      "The agreement on renegotiating the UK's EU membership was announced by European Council president Donald Tusk, who tweeted: \"Deal. Unanimous support for new settlement for #UKinEU.\"\n",
      "German Chancellor Angela Merkel predicted the package of reforms would \"elicit support in the UK for the country to remain in the EU\".\n",
      "Mr Tusk said it \"strengthens Britain's special status\", while EU Commission president Jean-Claude Juncker described it as \"fair\".\n",
      "Mr Tusk added: \"We didn't walk away from the negotiating table. We were willing to sacrifice part of our interests for the common good, to show our unity.\n",
      "\"I deeply believe the UK needs Europe and Europe needs the UK. But the final decision is in the hands of the British people.\"\n",
      "The ink is hardly dry on the UK's EU deal, but immediately the focus has switched to the substance of what David Cameron has achieved and - possibly an awkward question - how many of his colleagues will argue against him.\n",
      "The focus will move to whether the prime minister can keep his party politely together during a period of public disagreement.\n",
      "The ability to restrict benefits to migrants is an important victory for Mr Cameron - ammunition for his argument that he has achieved changes to help reduce the number of EU migrants coming to live and work in the UK.\n",
      "The proposals are complicated and do not exactly match the promises he made in the Conservative Party manifesto.\n",
      "But with it - and the other commitments - it becomes harder for his critics to make the case that the agreement is flimsy and will change nothing.\n",
      "Read more from Laura\n",
      "Mr Cameron said he had achieved the reforms he wanted, claiming they would put the UK \"in the driving seat\" of one of the world's biggest markets and create a \"more flexible\" EU.\n",
      "\"We have permanently protected the pound and our right to keep it,\" he added, saying that, for the first time, the EU \"has explicitly acknowledged it has more than one currency\".\n",
      "The prime minister said he had also protected Britain from further political integration inside the EU, adding: \"Let me put this as simply as I can: Britain will never be part of a European superstate.\"\n",
      "Outlining his case to remain \"in a reformed Europe\", Mr Cameron said \"turning our back on the EU is no solution at all\".\n",
      "\"We should be suspicious of those who claim that leaving Europe is an automatic fast-track to a land of milk and honey,\" he added.\n",
      "\"The British people must now decide whether to stay in this reformed European Union or to leave. This will be a once-in-a-generation moment to shape the destiny of our country.\"\n",
      "Labour leader Jeremy Corbyn dismissed Mr Cameron's deal as a \"sideshow\" designed to \"appease his opponents in the Conservative Party,\" adding that he had done nothing to protect jobs and fight low pay.\n",
      "\"We will be campaigning to keep Britain in Europe in the coming referendum, regardless of David Cameron's tinkering, because it brings investment, jobs and protection for British workers and consumers,\" he said.\n",
      "Scotland's First Minister Nicola Sturgeon said it was now \"more important than ever\" that those who supported Scotland's continued EU membership made the case \"as strongly as possible\".\n",
      "Eurosceptics have dismissed the reforms, saying they will not allow the UK to block unwanted EU laws or reduce migration.\n",
      "Matthew Elliott, chief executive of the Vote Leave campaign, said Mr Cameron \"will now declare victory but it is an entirely hollow one\".\n",
      "UKIP leader Nigel Farage tweeted: \"This is a truly pathetic deal. Let's Leave the EU, control our borders, run our own country and stop handing Â£55m every day to Brussels. I believe in Britain. We are good enough to be an independent, self-governing nation outside of the EU. This is our golden opportunity.\"\n",
      "As the EU summit was being concluded, another EU exit campaign, Grassroots Out, held a rally in Westminster.\n",
      "Conservative MP David Davis said it was time for Britain \"to take  control of its own destiny\", while UKIP leader Nigel Farage said the cross-party campaign was \"absolutely united in fighting to get back our democracy\".\n",
      "Mr Farage unveiled former Respect MP George Galloway as a \"special guest\" at the rally, describing him as a \"towering figure on the left of British politics\".\n"
     ]
    }
   ],
   "source": [
    "# selected_data - dict with keys: (id, document, true_summary, (factuality_data, faithfulness_data))\n",
    "selected_data = xsum_test_data.data_by_id[bbc_id]\n",
    "\n",
    "# original_docs - documents to sumamrize\n",
    "original_doc = selected_data[\"document\"]\n",
    "true_summary = selected_data[\"true_summary\"]\n",
    "print(\"original doc to summarize:\\n\", original_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54935fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ood doc to summarize:\n",
      " The team is processing satellite images to show how rocks in a belt that stretches from Europe's Alps to China are slowly accumulating strain.\n",
      "Movements on the scale of just millimetres per year are being sought.\n",
      "The new maps are being made available to help researchers produce more robust assessments of seismic hazard.\n",
      "The kind of change they are trying to chart is not noticeable in the everyday human sense, but over time will put faults under such pressure that they eventually rupture - often with catastrophic consequences.\n",
      "\"We may well discover regions that have very small strain rates that we have not been able to detect before,\" said Dr Richard Walters.\n",
      "\"And that may well tell us that earthquakes are more likely in some areas that traditionally have been thought of as being completely stable and not at risk of having earthquakes at all.\"\n",
      "Dr Walters is affiliated to the UK Centre for Observation and Modelling of Earthquakes, Volcanoes and Tectonics (COMET).\n",
      "He announced the start of the new service here in San Francisco, at the Fall Meeting of the American Geophysical Union.\n",
      "Key to the UK scientists' work is the high performance of the EU's new Sentinel-1 radar satellites.\n",
      "This pair of spacecraft repeatedly and rapidly image the surface of the globe, throwing their data to the ground using a high-speed laser link. And by comparing whole stacks of their pictures in a technique known as interferometry, the COMET group can begin to see the very slow bending and buckling that occurs in the crust as a result of shifting tectonic plates.\n",
      "To initiate the service, the researchers are concentrating on the Alpine-Himalayan seismic belt.\n",
      "This is the sector where most of the deaths arising from big earthquakes occur.\n",
      "In time, however, the mapping exercise will be extended to cover all major seismic hazard zones, including the rim of the Pacific basin - the so-called \"ring of fire\", where large tremors are also a regular occurrence.\n",
      "To be really effective, the team's maps need to be sensitive to movements of about 1mm per year over 100km.\n",
      "The system is not quite there yet, but as the Sentinels gather more and more images, the desired standard should be realised.\n",
      "As a proof of principle - and to give an example of what the new system can do - the COMET group showed off its maps of Turkey at AGU.\n",
      "These capture the 20-25mm/year westwards march of the Anatolian plateau relative to Eurasia.\n",
      "The focus of interest is how tectonic strain is building up along the North and East Anatolian Faults - the trigger points for so many damaging quakes in the past.\n",
      "Prof Tim Wright, the director of COMET, said one of the breakthroughs that had made the new service possible was simply the prodigious volumes of data the Sentinel satellite system could now feed to the ground.\n",
      "\"To give you an example, in just one year of Sentinel operation there are 156 terabytes of data; whereas the entire 10-year archive of Envisat (a previous European radar satellite) has just 24TB.\n",
      "\"And we now process the data from the Sentinels automatically within a few hours of getting it.\"\n",
      "Dr Walters added: \"This is a big data project. We've had funding from the UK's Natural Environment Research Council to build a big data-processing facility, to take these data from the European Space Agency, which they provide for free, and make useful geophysical measurements.\n",
      "\"We then serve that to the community. We put the data out there not just for us to analyse and think about seismic hazards, but for scientists all over the world to use.\"\n",
      "The \"Looking inside the Continents from Space\" project has just sent live a website where all the processed maps can be accessed.\n",
      "COMET is also working on a very similar system that would allow scientists to track the behaviour of volcanoes. The Sentinels will also see their slow developing bulges of magma that may precede eruptions.\n",
      "Jonathan.Amos-INTERNET@bbc.co.uk and follow me on Twitter: @BBCAmos\n"
     ]
    }
   ],
   "source": [
    "# sample one bbcid\n",
    "ood_id = random.choice(list(xsum_test_data.data_by_id.keys()))\n",
    "ood_selected_data = xsum_test_data.data_by_id[ood_id]\n",
    "\n",
    "# original_docs - documents to sumamrize\n",
    "ood_doc = ood_selected_data[\"document\"]\n",
    "print(\"ood doc to summarize:\\n\", ood_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cb9af",
   "metadata": {},
   "source": [
    "## analyze beam search output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1ccb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_xsum_summary import load_summarization_model_and_tokenizer, generate_summaries, generate_token_entropy_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407ba6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c662c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-xsum\"\n",
    "model, tokenizer = load_summarization_model_and_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26105f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inputs = tokenizer(\n",
    "    original_doc,\n",
    "    # max_length=1024,  # default is 1024 for 'facebook/bart-large-xsum'\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "input_token_ids = inputs.input_ids.to(device)\n",
    "attention_mask = inputs.attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dd922e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "ood_inputs = tokenizer(\n",
    "    ood_doc,\n",
    "    # max_length=1024,  # default is 1024 for 'facebook/bart-large-xsum'\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "ood_input_token_ids = ood_inputs.input_ids.to(device)\n",
    "ood_attention_mask = ood_inputs.attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df469b1",
   "metadata": {},
   "source": [
    "## Generate beam-search output\n",
    "---\n",
    "(https://huggingface.co/docs/transformers/main/en/internal/generation_utils#transformers.generation_utils.BeamSearchEncoderDecoderOutput)\n",
    "\n",
    "* **sequences** (torch.LongTensor of shape (batch_size*num_return_sequences, sequence_length))\n",
    "    * The generated sequences. The second dimension (sequence_length) is either equal to max_length or shorter if all batches finished early due to the eos_token_id.\n",
    "\n",
    "* **sequences_scores** (torch.FloatTensor of shape (batch_size*num_return_sequences), optional, returned when output_scores=True is passed or when config.output_scores=True)\n",
    "    * Final beam scores of the generated sequences.\n",
    "\n",
    "* **scores** (tuple(torch.FloatTensor) optional, returned when output_scores=True is passed or when config.output_scores=True)\n",
    "    * Beam transition scores for each vocabulary token at each generation step. Beam transition scores consisting of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam. (max_length-1,)-shaped tuple of torch.FloatTensor with each tensor of shape (batch_size*num_beams, config.vocab_size)).\n",
    "\n",
    "* **beam_indices** (tuple(tuple(torch.LongTensor)), optional, returned when output_scores=True is passed or when config.output_scores=True)\n",
    "    * Beam indices of generated token id at each generation step. (batch_size*num_return_sequences)-shaped tuple of (max_length-1,)-shaped tuples of scalar torch.LongTensor tensors.\n",
    "\n",
    "* \\+ attentions, hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13d625be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26739dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.random.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7488f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cc65779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 3            |        cudaMalloc retries: 3         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   22957 MB |   22957 MB |   49934 MB |   26977 MB |\n",
      "|       from large pool |   22952 MB |   22952 MB |   49906 MB |   26953 MB |\n",
      "|       from small pool |       5 MB |       6 MB |      28 MB |      23 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   22957 MB |   22957 MB |   49934 MB |   26977 MB |\n",
      "|       from large pool |   22952 MB |   22952 MB |   49906 MB |   26953 MB |\n",
      "|       from small pool |       5 MB |       6 MB |      28 MB |      23 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   22984 MB |   23134 MB |   23414 MB |  440320 KB |\n",
      "|       from large pool |   22978 MB |   23126 MB |   23402 MB |  434176 KB |\n",
      "|       from small pool |       6 MB |       8 MB |      12 MB |    6144 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   27159 KB |   83039 KB |    5966 MB |    5940 MB |\n",
      "|       from large pool |   26416 KB |   82768 KB |    5932 MB |    5906 MB |\n",
      "|       from small pool |     743 KB |    3031 KB |      34 MB |      33 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     574    |     574    |    1710    |    1136    |\n",
      "|       from large pool |     228    |     229    |    1063    |     835    |\n",
      "|       from small pool |     346    |     348    |     647    |     301    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     574    |     574    |    1710    |    1136    |\n",
      "|       from large pool |     228    |     229    |    1063    |     835    |\n",
      "|       from small pool |     346    |     348    |     647    |     301    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     100    |     104    |     111    |      11    |\n",
      "|       from large pool |      97    |     100    |     105    |       8    |\n",
      "|       from small pool |       3    |       4    |       6    |       3    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      15    |      17    |     756    |     741    |\n",
      "|       from large pool |       8    |      10    |     614    |     606    |\n",
      "|       from small pool |       7    |       9    |     142    |     135    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd13442c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 240.00 MiB (GPU 0; 23.65 GiB total capacity; 22.42 GiB already allocated; 181.44 MiB free; 22.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m beam_multi_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_token_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.92\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;43;03m#     num_beams=num_beams,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;43;03m#     max_length=150,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;43;03m#     early_stopping=False,  # check\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;43;03m#     return_dict_in_generate=True,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;43;03m#     output_scores=True,\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_utils.py:1265\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1257\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m num_return_sequences,\n\u001b[1;32m   1258\u001b[0m     num_beams\u001b[38;5;241m=\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     do_early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[1;32m   1262\u001b[0m )\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;66;03m# 12. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[0;32m-> 1265\u001b[0m input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_expand_inputs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_sample(\n\u001b[1;32m   1274\u001b[0m     input_ids,\n\u001b[1;32m   1275\u001b[0m     beam_scorer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1285\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_utils.py:581\u001b[0m, in \u001b[0;36mGenerationMixin._expand_inputs_for_generation\u001b[0;34m(input_ids, expand_size, is_encoder_decoder, attention_mask, encoder_outputs, **model_kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `is_encoder_decoder` is True, make sure that `encoder_outputs` is defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 581\u001b[0m     encoder_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_return_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m encoder_outputs\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_ids, model_kwargs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 240.00 MiB (GPU 0; 23.65 GiB total capacity; 22.42 GiB already allocated; 181.44 MiB free; 22.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "beam_multi_output = model.generate(\n",
    "    input_token_ids,\n",
    "    do_sample=True, \n",
    "    max_length=100, \n",
    "    top_p=0.92, \n",
    "    top_k=0,\n",
    "    num_return_sequences=100,\n",
    "    \n",
    "#     num_beams=num_beams,\n",
    "#     max_length=150,\n",
    "#     early_stopping=False,  # check\n",
    "#     return_dict_in_generate=True,\n",
    "#     output_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c385cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_es_multi_output = model.generate(\n",
    "    input_token_ids,\n",
    "    num_beams=num_beams,\n",
    "    num_return_sequences=num_beams,\n",
    "    max_length=150,\n",
    "    early_stopping=True,  # check\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb7d5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with other EU leaders to renegotiate its membership.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with EU leaders to renegotiate the country\\'s membership.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after agreeing a deal with other EU leaders to stay in the bloc.',\n",
       " 'David Cameron has said the UK will never be part of a \" European superstate\" after reaching a deal with other EU leaders to renegotiate its membership.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with other EU leaders on renegotiating its membership.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with EU leaders to renegotiate its membership.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with EU leaders to keep the country in the EU.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with EU leaders to keep the country in the bloc.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after agreeing a deal with other EU leaders to stay in the EU.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with other EU leaders on membership.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(\n",
    "    seq, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "for seq in beam_es_multi_output.sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57d60b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"David Cameron has said he has achieved the reforms he wanted in the UK's renegotiations with the European Union.\",\n",
       " 'David Cameron has said the UK will \"never be part of a European superstate\" after securing a deal to stay in the EU.',\n",
       " 'David Cameron has said the UK\\'s \"special status\" in the European Union has been secured in a deal with other EU leaders.',\n",
       " 'David Cameron has said he has secured a \"historic deal\" on the UK\\'s membership of the European Union.',\n",
       " \"David Cameron has said he has achieved the reforms he wanted in the UK's renegotiations with the European Union.\",\n",
       " 'David Cameron has said the UK\\'s deal to renegotiate its membership of the European Union is a \"once-in-a-generation moment\" for Britain.',\n",
       " 'David Cameron has said the UK will \"never be part of a European superstate\" after reaching a deal with EU leaders to renegotiate the country\\'s membership.',\n",
       " 'David Cameron has said the UK will never be part of a \"European superstate\" after reaching a deal with other EU leaders to renegotiate the country\\'s membership.',\n",
       " 'David Cameron has said he has secured a \"significant deal\" on the UK\\'s membership of the European Union.',\n",
       " 'David Cameron has said the UK\\'s \"special status\" within the EU has been secured in a deal with other EU leaders.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(\n",
    "    seq, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "for seq in beam_multi_output] #.sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96fa02c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David Cameron says a deal struck with EU leaders will give the UK \"special status\" and he will campaign with his \"heart and soul\" to stay in the union.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_selected_logit = torch.index_select(logits, 0, beam_indices)[0][None, :] # -> 1, 33, 50264\n",
    "tmp_selected_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a8cece51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,  8773,  5628,    34,    26,     5,   987,    40,   393,    28,\n",
       "          233,     9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,\n",
       "           10,   432,    19,    97,  1281,   917,     7, 20663,   877,     5,\n",
       "          247,    18,  6332,     4,     2], device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_multi_output.sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff733d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6115, -0.6121, -0.6239, -0.6271, -0.6271, -0.6273, -0.6303, -0.6460,\n",
       "        -0.6462, -0.6574], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_multi_output.sequences_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9fb02aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 33])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove sos token\n",
    "gen_sequences = beam_multi_output.sequences[:, 1:]\n",
    "gen_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6fed2751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,    97,  1281,   917,     7, 20663,   877,    63,  6332,\n",
       "             4,     2,  -100],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,  1281,   917,     7, 20663,   877,     5,   247,    18,\n",
       "          6332,     4,     2],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71, 14176,    10,\n",
       "           432,    19,    97,  1281,   917,     7,  1095,    11,     5,  7667,\n",
       "             4,     2,  -100],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22,   796,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,    97,  1281,   917,     7, 20663,   877,    63,  6332,\n",
       "             4,     2,  -100],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,    97,  1281,   917,    15, 20663,  1295,    63,  6332,\n",
       "             4,     2,  -100],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,  1281,   917,     7, 20663,   877,    63,  6332,     4,\n",
       "             2,  -100,  -100],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,  1281,   917,     7,   489,     5,   247,    11,     5,\n",
       "          1281,     4,     2],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,  1281,   917,     7,   489,     5,   247,    11,     5,\n",
       "          7667,     4,     2],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71, 14176,    10,\n",
       "           432,    19,    97,  1281,   917,     7,  1095,    11,     5,  1281,\n",
       "             4,     2,  -100],\n",
       "        [ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,    97,  1281,   917,    15,  6332,     4,     2,  -100,\n",
       "          -100,  -100,  -100]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_labels = gen_sequences.masked_fill(gen_sequences==tokenizer.pad_token_id, -100)\n",
    "gen_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd6014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8532b5b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_pad = (gen_sequences != tokenizer.pad_token_id)  # False if padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25769791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 33, 50264])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's stack the logits generated at each step to a tensor and transform\n",
    "# logits to probs\n",
    "probs = torch.stack(gen_output.scores, dim=1).softmax(-1)  # -> shape [3, 15, vocab_size]\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b58337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 33])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to collect the probability of the generated token\n",
    "# we need to add a dummy dim in the end to make gather work\n",
    "gen_probs = torch.gather(probs, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
    "gen_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41df1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask pad tokens\n",
    "gen_probs = gen_probs.masked_fill(not_pad==0, -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d53bc55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-123.5888, -195.8047, -255.2489, -250.1562, -185.2542, -261.7501,\n",
       "        -291.4669, -256.7234, -215.1470, -266.0401], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_probs.log().nansum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f215f",
   "metadata": {},
   "source": [
    "## test with just one sequence\n",
    "---\n",
    "### 1. Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "374c2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "542a3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_output = model.generate(\n",
    "    input_token_ids,\n",
    "    num_beams=1,\n",
    "    num_return_sequences=1,\n",
    "    max_length=150,\n",
    "    early_stopping=True,  # check\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f7e87fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David Cameron has said he has secured a \"significant\" deal with EU leaders on the UK\\'s membership.'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the generated summary\n",
    "gen_sum = tokenizer.decode(\n",
    "        beam_output.sequences[0], skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "gen_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8577ceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated sequence - remove sos token\n",
    "gen_sequences = beam_output.sequences[:, 1:]\n",
    "gen_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa10520",
   "metadata": {},
   "source": [
    "* stack **logits** and collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70208823",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_scores = beam_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24df28dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 50264])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_logits_all = torch.stack(beam_scores, dim=1)\n",
    "beam_logits_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88eccb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_logit = torch.gather(beam_logits_all, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
    "beam_logit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3f6c7",
   "metadata": {},
   "source": [
    "* stack **probs** and collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceea16d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 50264])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_probs_all = torch.stack(beam_scores, dim=1).softmax(-1)  # -> shape [3, 15, vocab_size]\n",
    "beam_probs_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8fb4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_probs = torch.gather(beam_probs_all, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
    "beam_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22323d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-17.2895], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_probs.log().nansum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6ad69",
   "metadata": {},
   "source": [
    "* maybe I should include beam indices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d40c9e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 3, 1, 8, 4, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 3, 7, 5, 1], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_indices = torch.stack(beam_output.beam_indices[0], dim=0)\n",
    "beam_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06631b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 33, 50264])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.zeros((len(gen_sequences[0]) + 1, tokenizer.vocab_size - 1)).to(device)\n",
    "\n",
    "for token_index, (beam_idx, beam_score) in enumerate(zip(beam_indices, beam_scores)):\n",
    "    stacked[token_index,:] = beam_score[beam_idx]\n",
    "\n",
    "stacked = stacked[None, :]\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7516e5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_gen_logits = torch.gather(stacked, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
    "tmp_gen_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2b250e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.7450,  -7.7351, -10.7854, -11.3415, -10.4671, -12.7027,  -1.6221,\n",
       "          -7.2993, -10.0530,  -0.6768,  -0.0911, -14.9387,  -2.5317, -11.8655,\n",
       "          -0.0671,  -0.0310,  -0.2152,  -0.3412,  -1.9294,  -0.2500,  -0.9693,\n",
       "          -0.6250,  -1.4357,  -7.9370,  -0.4833,  -8.0090,  -1.6379,  -0.0937,\n",
       "          -0.9335,  -0.2856,  -9.3447,  -0.1209]], device='cuda:0')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_gen_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592f4bf",
   "metadata": {},
   "source": [
    "* model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4382f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(input_ids=input_token_ids, labels=gen_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d8cbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8773,  5628,    34,    26,    37,    34,  5288,    10,    22, 18880,\n",
       "           113,   432,    19,  1281,   917,    15,     5,   987,    18,  6332,\n",
       "             4,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7817fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_probs_all = model_output.logits.softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "675ffbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_probs_all.max(-1).indices == gen_sequences  # max is not always label sequences with beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0c4aa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 50264])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_probs_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08252316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_probs = torch.gather(model_probs, 2, gen_sequences[:, :, None]).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f00a9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23078cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log prob of the sequence = - loss\n",
    "-model_probs.log().mean() == model_output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e24d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob = -model_output.loss*len(gen_sequences[0])  # do we need to take product of sequence length?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8b33c",
   "metadata": {},
   "source": [
    "* get batched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1d8fd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_multi_output = model(input_ids=input_token_ids.repeat(num_beams, 1), labels=gen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2e243290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_first_output = model(input_ids=input_token_ids, labels=gen_labels[0, :-1][None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7dd98428",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_second_output = model(input_ids=input_token_ids, labels=gen_labels[1, :][None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7530044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "808dcc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_multi = criterion(model_multi_output.logits.permute(0,2,1), gen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5454f490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 33])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "59e44043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-19.5676, -20.1987, -19.9657, -20.0667, -20.0671, -19.4462, -20.8011,\n",
       "        -21.3187, -20.6768, -19.0633], device='cuda:0')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_losses = -loss_multi.masked_fill(loss_multi==0., torch.nan).nansum(1)\n",
    "seq_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e289e94",
   "metadata": {},
   "source": [
    "* ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4b1078bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ood_model_multi_output = model(input_ids=ood_input_token_ids.repeat(num_beams, 1), labels=gen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "422563fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_loss_multi = criterion(ood_model_multi_output.logits.permute(0,2,1), gen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7fe08b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-144.3786, -141.6270, -145.0091, -146.9162, -150.7780, -139.9524,\n",
       "        -140.1727, -143.6599, -143.9860, -143.6413], device='cuda:0')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_seq_losses = -ood_loss_multi.masked_fill(ood_loss_multi==0., torch.nan).nansum(1)\n",
    "ood_seq_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b486324d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([124.8110, 121.4283, 125.0434, 126.8494, 130.7109, 120.5062, 119.3715,\n",
       "        122.3412, 123.3092, 124.5780], device='cuda:0')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_losses - ood_seq_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ad5af472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(123.8949, device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(seq_losses-ood_seq_losses) / num_beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c935e811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6034, -0.6115, -0.6121, -0.6239, -0.6271, -0.6271, -0.6273, -0.6303,\n",
       "        -0.6365, -0.6401], device='cuda:0')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_multi_output.sequences_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d923ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob = -model_output.loss*len(gen_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c2fed28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 33])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9356e",
   "metadata": {},
   "source": [
    "* how the loss is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a153fa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 50264])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "11a5c4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8773,  5628,    34,    26,     5,   987,    40,   393,    28,   233,\n",
       "             9,    10,    22, 17108,  2422,  4897,   113,    71,  3970,    10,\n",
       "           432,    19,    97,  1281,   917,     7, 20663,   877,    63,  6332,\n",
       "             4,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "27b3ea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.5911, device='cuda:0')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.logits[0][1][gen_sequences[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "69dce706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.4391, 13.5911, 12.9642, 12.7980, 11.7870, 13.7139, 12.1136, 12.4357,\n",
       "         13.0785, 13.0724, 13.3151, 13.0819, 13.5901, 13.9457, 14.9705, 16.1668,\n",
       "         13.1780, 12.9528, 11.8507, 13.5252, 13.6520, 12.9519, 12.4470, 14.7332,\n",
       "         13.7435, 12.3594, 12.0541, 14.5040, 11.8986, 14.0034, 13.2752, 13.1118]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logits = torch.gather(model_output.logits, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
    "model_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "19e03a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.7450,  -0.1185,  -0.4535,  -0.9146,  -1.3093, -12.5437,  -9.6778,\n",
       "         -11.7671, -11.8425, -16.4339, -16.9507,  -0.2015,  -0.3638,  -0.8337,\n",
       "          -0.0625,  -0.0311,  -0.2149,  -0.3307,  -1.9473,  -0.2904,  -0.5547,\n",
       "          -0.6038,  -1.4306,  -0.2682, -11.4617,  -1.0268,  -2.3290, -11.0826,\n",
       "          -0.9402,  -6.5864,  -0.1513,  -0.1212]], device='cuda:0')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a60bc2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.7450,  -7.7351, -10.7854, -11.3415, -10.4671, -12.7027,  -1.6221,\n",
       "          -7.2993, -10.0530,  -0.6768,  -0.0911, -14.9387,  -2.5317, -11.8655,\n",
       "          -0.0671,  -0.0310,  -0.2152,  -0.3412,  -1.9294,  -0.2500,  -0.9693,\n",
       "          -0.6250,  -1.4357,  -7.9370,  -0.4833,  -8.0090,  -1.6379,  -0.0937,\n",
       "          -0.9335,  -0.2856,  -9.3447,  -0.1209]], device='cuda:0')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_gen_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57a387c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(model_logits, gen_logits)  # logits are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd452e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38228f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# loss is - negative log probability\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;241m-\u001b[39m\u001b[43mmodel_probs\u001b[49m\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m==\u001b[39m model_output\u001b[38;5;241m.\u001b[39mloss\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_probs' is not defined"
     ]
    }
   ],
   "source": [
    "# loss is - negative log probability\n",
    "-model_probs.log().mean() == model_output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87538c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfd61757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7859, device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf163d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 33, 50264])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e069dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_probs = torch.gather(logits, 2, gen_sequences[:, :, None]).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8ae88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(input_ids=input_token_ids, labels=gen_output.sequences[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a9c21431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 50264])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bec8158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3801, device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_probs = model_output.logits.softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8455ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_output\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_output' is not defined"
     ]
    }
   ],
   "source": [
    "model_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76b17401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50264])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_output.scores[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b37da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1480e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(input_ids=input_token_ids.repeat(num_beams, 1), labels=model_output.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16935921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01508850",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_probs = torch.tensor([[0.1, 0.2, 0.7], [0.2, 0.3, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "687c54de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0140, 0.0300])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_probs.prod(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b21072f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.2687, -3.5066])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_probs.log().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70a81c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3403, 4.2200])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_probs.logsumexp(1).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73501227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79b38f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 34])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4447666",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch[“targets”][eval_batch[“targets”]==tokenizer.convert_tokens_to_ids(tokenizer.pad_token)] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ab81b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1024])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_ids.repeat(num_beams, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46d89301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 34])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf15d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_token_ids.repeat(num_beams, 1), labels=model_output.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bbc23cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "45d1ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b00f0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "781c2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c323b2c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [112]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "94f2442a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2923, 0.3051, 0.3011, 0.3032, 0.3042, 0.2882, 0.3183, 0.3297, 0.3172,\n",
       "        0.2812], device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(logits.permute(0,2,1), model_output.sequences).mean(dim=1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d15af2b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Seq2SeqLMOutput' object has no attribute 'sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [123]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gen_sequences \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequences\u001b[49m[:, input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:]\n\u001b[1;32m      2\u001b[0m gen_sequences\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Seq2SeqLMOutput' object has no attribute 'sequences'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac369058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20473a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5751df",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(outputs.logits, )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6235329e4e80563f0f629f7d03bff3ed38888b52eb6adc0ce82f2c2e907be760"
  },
  "kernelspec": {
   "display_name": "xsum_analysis",
   "language": "python",
   "name": "xsum_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
