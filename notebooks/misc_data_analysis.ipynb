{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc74bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xsum_dataset import XsumDataset\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77386b",
   "metadata": {},
   "source": [
    "## 1. check if train/val/test has the same structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0051404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/wk247/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcbc6e2569a43da9c65ec675d588190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsum_data_raw = datasets.load_dataset(\"xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d54dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = XsumDataset(xsum_data_raw[\"train\"])\n",
    "val_data = XsumDataset(xsum_data_raw[\"validation\"])\n",
    "test_data = XsumDataset(xsum_data_raw[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d6bb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'document', 'true_summary', 'factuality_data', 'faithfulness_data']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset keys\n",
    "keys = list(train_data.dataset[0].keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc449cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train_data, val_data, test_data]:\n",
    "    for sample in dataset:\n",
    "        if list(sample.keys()) != keys:  # if the sample has different keys\n",
    "            print(sample.keys())\n",
    "            assert(False)\n",
    "        if sample[\"factuality_data\"] != {}:  # if there is factuality data\n",
    "            print(sample)\n",
    "            assert(False)\n",
    "        if sample[\"faithfulness_data\"] != {}:  # if there is faithfulness data\n",
    "            print(sample)\n",
    "            assert(False)\n",
    "        if len(sample[\"true_summary\"]) == 0:  # if the sample doesn't have true summary\n",
    "            print(sample)\n",
    "            assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5ff0a",
   "metadata": {},
   "source": [
    "## concat train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0ce90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_data_raw_cc = datasets.concatenate_datasets(\n",
    "    [xsum_data_raw[\"train\"], xsum_data_raw[\"validation\"], xsum_data_raw[\"test\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a83829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary', 'id'],\n",
       "    num_rows: 226711\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_data_raw_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9837e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_concat_data = XsumDataset(xsum_data_raw_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e775e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226711"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xsum_concat_data.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e88231",
   "metadata": {},
   "source": [
    "# 2. take 'generate_summaries' apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476a1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from utils import entropy\n",
    "from generate_xsum_summary import load_summarization_model_and_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49e2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-xsum\"\n",
    "model, tokenizer = load_summarization_model_and_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b640d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_to_summarize = [\n",
    "    \"Load summary generation model and move to GPU, if possible.\",\n",
    "    \"Given a trained summary generation model and appropriate tokenizer,\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c8ea2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 47167, 4819, 2706, 1421, 8, 517, 7, 22794, 6, 114, 678, 4, 2], [0, 18377, 10, 5389, 4819, 2706, 1421, 8, 3901, 19233, 6315, 6, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(docs_to_summarize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c0e82",
   "metadata": {},
   "source": [
    "## inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd3ede1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    docs_to_summarize,\n",
    "    # max_length=1024,  # default is 1024 for 'facebook/bart-large-xsum'\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "input_token_ids = inputs.input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bada5aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 47167,  4819,  2706,  1421,     8,   517,     7, 22794,     6,\n",
       "           114,   678,     4,     2],\n",
       "        [    0, 18377,    10,  5389,  4819,  2706,  1421,     8,  3901, 19233,\n",
       "          6315,     6,     2,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1ba083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 1, 50264]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special ids\n",
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31da71bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Load',\n",
       " 'Ġsummary',\n",
       " 'Ġgeneration',\n",
       " 'Ġmodel',\n",
       " 'Ġand',\n",
       " 'Ġmove',\n",
       " 'Ġto',\n",
       " 'ĠGPU',\n",
       " ',',\n",
       " 'Ġif',\n",
       " 'Ġpossible',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert_ids_to_tokens\n",
    "tokenizer.convert_ids_to_tokens(input_token_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972db38",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f0acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.generate(\n",
    "    input_token_ids,\n",
    "    num_beams=4,\n",
    "    max_length=150,\n",
    "    early_stopping=True,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2d27220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you are using a computer with a high-performance graphics card, you may need to change the way you load data.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode first model output\n",
    "tokenizer.decode(\n",
    "    model_output.sequences[0], skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67363423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you are using a computer with a high-performance graphics card, you may need to change the way you load data.',\n",
       " 'The following is a list of some of the most popular phrases in the English language.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode all outputs\n",
    "generated_summaries = [\n",
    "    tokenizer.decode(\n",
    "        id, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    for id in model_output.sequences\n",
    "]\n",
    "generated_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00fc77",
   "metadata": {},
   "source": [
    "## sequence metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba20cdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 47167,\n",
       " 4819,\n",
       " 2706,\n",
       " 1421,\n",
       " 8,\n",
       " 517,\n",
       " 7,\n",
       " 22794,\n",
       " 6,\n",
       " 114,\n",
       " 678,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 18377,\n",
       " 10,\n",
       " 5389,\n",
       " 4819,\n",
       " 2706,\n",
       " 1421,\n",
       " 8,\n",
       " 3901,\n",
       " 19233,\n",
       " 6315,\n",
       " 6,\n",
       " 2,\n",
       " 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten token ids\n",
    "input_set = input_token_ids.view(-1).tolist()\n",
    "input_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29e2565a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  1106,    47,    32,   634,    10,  3034,    19,    10,   239,\n",
       "            12, 15526, 12774,  1886,     6,    47,   189,   240,     7,   464,\n",
       "             5,   169,    47,  7511,   414,     4,     2],\n",
       "        [    2,   133,   511,    16,    10,   889,     9,   103,     9,     5,\n",
       "           144,  1406, 22810,    11,     5,  2370,  2777,     4,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76c5c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate metadata for one sequence\n",
    "seq_metadata = []\n",
    "for idx, output_token_id in enumerate(model_output.sequences[0][1:]):  # from the second token\n",
    "    beam_idx = model_output.beam_indices[0][idx]\n",
    "    selected_beam_probs = torch.exp(model_output.scores[idx][beam_idx])\n",
    "\n",
    "    # top alternatives during beam search\n",
    "    beam_top_alternatives = []\n",
    "    top_probs = torch.topk(selected_beam_probs, k=3)\n",
    "    for i, v in zip(top_probs.indices, top_probs.values):\n",
    "        beam_top_alternatives.append({\n",
    "            \"token\": tokenizer.decode(i),\n",
    "            \"token_id\": i.item(),\n",
    "            \"beam_token_prob\": v.item()\n",
    "        })\n",
    "\n",
    "    seq_metadata.append({\n",
    "        \"token_id\": output_token_id,\n",
    "        \"token\": tokenizer.decode(output_token_id),\n",
    "        \"entropy\": entropy(selected_beam_probs),  # entropy of the selected token\n",
    "        \"beam_token_prob\": selected_beam_probs[output_token_id].item(),  # prob of the selected token\n",
    "        \"beam_idx\": beam_idx.item(),  # beam index of the selected token\n",
    "        \"beam_top_probs\": beam_top_alternatives,  # token, token_id, prob of top K alternatives\n",
    "        \"token_in_input\": output_token_id in input_token_ids[0],  # is the selected token in its document? - use for overlap\n",
    "        # bug?\n",
    "        # \"token_in_input\": output_token_id in input_set\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3479c5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadatas are saved from the second token\n",
    "len(seq_metadata) == len(model_output.sequences[0]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ca11033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_id': tensor(1106, device='cuda:0'),\n",
       " 'token': 'If',\n",
       " 'entropy': 7.595674991607666,\n",
       " 'beam_token_prob': 0.04578085616230965,\n",
       " 'beam_idx': 0,\n",
       " 'beam_top_probs': [{'token': 'If',\n",
       "   'token_id': 1106,\n",
       "   'beam_token_prob': 0.04578085616230965},\n",
       "  {'token': 'Check',\n",
       "   'token_id': 26615,\n",
       "   'beam_token_prob': 0.021572448313236237},\n",
       "  {'token': 'As', 'token_id': 1620, 'beam_token_prob': 0.021526599302887917}],\n",
       " 'token_in_input': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20b2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate metadata for all sequences\n",
    "token_metadata = []\n",
    "for seq_idx in range(model_output.sequences.shape[0]):  # for each summary\n",
    "    seq_metadata = []\n",
    "    token_metadata.append(seq_metadata)\n",
    "    for idx, output_token_id in enumerate(model_output.sequences[seq_idx][1:]):\n",
    "        beam_idx = model_output.beam_indices[seq_idx][idx]\n",
    "        selected_beam_probs = torch.exp(model_output.scores[idx][beam_idx])\n",
    "\n",
    "        beam_top_alternatives = []\n",
    "        top_probs = torch.topk(selected_beam_probs, k=3)\n",
    "        for i, v in zip(top_probs.indices, top_probs.values):\n",
    "            beam_top_alternatives.append({\n",
    "                \"token\": tokenizer.decode(i),\n",
    "                \"token_id\": i.item(),\n",
    "                \"beam_token_prob\": v.item()\n",
    "            })\n",
    "\n",
    "        seq_metadata.append({\n",
    "            \"token_id\": output_token_id,\n",
    "            \"token\": tokenizer.decode(output_token_id),\n",
    "            \"entropy\": entropy(selected_beam_probs),\n",
    "            \"beam_token_prob\": selected_beam_probs[output_token_id].item(),\n",
    "            \"beam_idx\": beam_idx.item(),\n",
    "            \"beam_top_probs\": beam_top_alternatives,\n",
    "            \"token_in_input\": output_token_id in input_token_ids[0],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aedf3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_metadata)  # number of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc62986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6235329e4e80563f0f629f7d03bff3ed38888b52eb6adc0ce82f2c2e907be760"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('xsum_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
